{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width:100% } \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the sigmoid function $S(t) := \\large \\frac{1}{1 + \\exp(-t)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1.0 / (1.0 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using NumPy to compute $\\exp(t)$, we can feed this function with a `numpy` array to compute the sigmoid function for every element of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(np.array([-1.0, 0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the natural logarithm of the sigmoid function.  If we implement this as <tt>log(sigmoid(t))</tt> we will get overflow issues for negative values of $t$ such that $t < -1000$ as the expression <tt>np.exp(-t)</tt> will overflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute \n",
    "$$ \\ln\\bigl(S(-1000)\\bigr) = \\ln\\Bigl(\\frac{1}{1 + \\exp(1000)}\\Bigr) = - \\ln\\bigl(1 + \\exp(1000)\\bigr) \\approx -1000. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(1 + np.exp(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we expected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, for $t < -100$ we have that $1 + \\exp(-t) \\approx \\exp(-t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1 + np.exp(-(-100)) == np.exp(-(-100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if $t < -100$ we have:\n",
    "$$ \n",
    "\\begin{array}{lcl}\n",
    "         \\ln\\left(\\large\\frac{1}{1+\\exp(-t)}\\right) \n",
    "  & = & -\\ln\\bigl(1+\\exp(-t)\\bigr) \\\\\n",
    "  & \\approx & -\\ln\\bigl(\\exp(-t)\\bigr)  \\\\\n",
    "  & = & t\n",
    "\\end{array}\n",
    "$$\n",
    "Hence $\\ln\\bigl(S(t)\\bigr) \\approx t$ for $t < -100$. The following implementation uses this approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSigmoid(t):\n",
    "    if t > -100:\n",
    "        return -np.log(1.0 + np.exp(-t))\n",
    "    else:\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{ll}(\\textbf{X}, \\textbf{y},\\textbf{w})$ is mathematically defined as follows:\n",
    "$$\\ell\\ell(\\mathbf{X},\\mathbf{y},\\mathbf{w}) = \n",
    " \\sum\\limits_{i=1}^N \\ln\\Bigl(S\\bigl(y_i \\cdot(\\mathbf{x}_i \\cdot \\mathbf{w})\\bigr)\\Bigr) =\n",
    " \\sum\\limits_{i=1}^N L\\bigl(y_i \\cdot(\\mathbf{x}_i \\cdot \\mathbf{w})\\bigr)\n",
    "$$\n",
    "The arguments $\\textbf{X}$, $\\textbf{y}$, and $\\textbf{w}$ are interpreted as follows:\n",
    "<ul>\n",
    "    <li> $\\textbf{X}$ is the feature matrix, $\\textbf{X}[i]$ is the $i$-th feature vector, i.e we have\n",
    "         $\\textbf{X}[i] = \\textbf{x}_i$ if we regard $\\textbf{x}_i$ as a row vector.\n",
    "         <p>It is assumed that $\\textbf{X}[i][0]$ is 1.0 for all $i$.</p>\n",
    "    </li>\n",
    "    <li> $\\textbf{y}$ is the output vector, $\\textbf{y}[i] \\in \\{-1,+1\\}$ for all $i$.</li> \n",
    "    <li> $\\textbf{w}$ is the weight vector.</li>\n",
    "</ul>\n",
    "$\\texttt{ll}(\\textbf{X}, \\textbf{y},\\textbf{w})$ computes the <font color=\"blue\">likelihood</font> of the weight vector $\\textbf{w}$\n",
    "given the observations $\\textbf{X}$ and $\\textbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll(X, y, w):   \n",
    "    return np.sum([logSigmoid(y[i] * (X[i] @ w)) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\mathtt{gradLL}(\\mathbf{x}, \\mathbf{y}, \\mathbf{w})$ computes the gradient of\n",
    "the log-lokelihood according to the formula\n",
    "$$ \\frac{\\partial\\quad}{\\partial\\, w_j}\\ell\\ell(\\mathbf{X},\\mathbf{y};\\mathbf{w}) =\n",
    "   \\sum\\limits_{i=1}^N y_i \\cdot x_{i,j} \\cdot  S(-y_i \\cdot \\mathbf{x}_i \\cdot \\mathbf{w}).\n",
    "$$\n",
    "The different components of this gradient are combined into a vector.\n",
    "The arguments are the same as the arguments to the function <tt>ll</tt> that computes the log-likelihood, i.e.\n",
    "<ul>\n",
    "    <li> $\\textbf{X}$ is the feature matrix, $\\textbf{X}[i]$ is the $i$-th feature vector, i.e we have\n",
    "    </li>\n",
    "    <li> $\\textbf{y}$ is the output vector, $\\textbf{y}[i] \\in \\{-1,+1\\}$ for all $i$.</li> \n",
    "    <li> $\\textbf{w}$ is the weight vector.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradLL(X, y, w):\n",
    "    Gradient = []\n",
    "    for j in range(len(X[0])):\n",
    "        L = [y[i] * X[i][j] * sigmoid(-y[i] * (X[i] @ w)) for i in range(len(X))]\n",
    "        Gradient.append(sum(L))\n",
    "    return np.array(Gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we want to investigate is stored in the file `'exam.csv'`.  The first column of this file is an integer from the set $\\{0,1\\}$.  The nuber is $0$ if the corresponding student has failed the exam and is $1$ otherwise.  The second column is a floating point number that lists the number of hours that the student has studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exam.csv') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    count  = 0  # line count\n",
    "    Pass   = []\n",
    "    Hours  = []\n",
    "    for row in reader:\n",
    "        if count != 0:  # skip header\n",
    "            Pass .append(float(row[0]))\n",
    "            Hours.append(float(row[1]))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed, we will plot the data points.  To this end we transform the lists `Pass` and `Hours` into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Pass)\n",
    "x = np.array(Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.set(style='darkgrid')\n",
    "plt.title('Pass/Fail vs. Hours of Study')\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.xlabel('Hours of Study')\n",
    "plt.ylabel('Pass = 1, Fail = 0')\n",
    "plt.yticks(np.arange(-0.0, 1.0, step=0.1))\n",
    "plt.scatter(x, y, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of students is stored in the variable `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to turn the vector `x` into the feature matrix `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(x, (n, 1))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepend the number $1.0$ in every row of `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(np.ones((n, 1)), X, axis=-1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the entries in the vector `y` are either $0$ or $1$.  These values need to be transformed to $-1$ and $+1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * y - 1\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have no real clue about the weights, we set them to $0$ initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradient_ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start   = np.zeros((2,))\n",
    "eps     = 10 ** -8\n",
    "f       = lambda w: ll(X, y, w)\n",
    "gradF   = lambda w: gradLL(X, y, w)\n",
    "w, _, _ = gradient_ascent.findMaximum(f, gradF, start, eps, True)\n",
    "beta    = w[0]\n",
    "gamma   = w[1]\n",
    "print(f'model: P(pass|hours) = S({beta} + {gamma} * hours)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this function together with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "sns.set(style='darkgrid')\n",
    "plt.title('Pass/Fail vs. Hours of Study')\n",
    "H = np.arange(0.0, 6.0, 0.05)\n",
    "P = sigmoid(beta + gamma * H)\n",
    "sns.lineplot(H, P, color='r')\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.xlabel('Hours of Study')\n",
    "plt.ylabel('Probability of Passing the Exam')\n",
    "plt.yticks(np.arange(-0.0, 1.01, step=0.1))\n",
    "plt.scatter(x, (y + 1) / 2, color='b')\n",
    "plt.savefig('exam-probability.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
