{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100%; !important } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Natural Language Toolkit (NLKT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the <a href=\"https://www.nltk.org\">Natural Language ToolKit</a> (NLKT).  Our first example is concerned with <em style=\"color:blue;\">classification</em>: We want to see whether it is possible to predict the gender of a given first name.  This example is taken from <a href=\"https://www.nltk.org/book/ch06.html\">Chapter 6</a> of the <a href=\"https://www.nltk.org/book\">NLTK book</a>.  To begin with, we import the module `nltk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1d2184025e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module provides a number of builtin datasets.  We will start by importing the object `names` from the module `nltk.corpus`.  The dataset `names` consists of a number of first names for both genders.  To be more precise, `names` is an object of class `nltk.corpus.util.LazyCorpusLoader` that provides methods to load both female and male first names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "type(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load these names into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FemaleNames = names.words('female.txt')\n",
    "MaleNames   = names.words('male.txt'  )\n",
    "print('Number of female first names:', len(FemaleNames))\n",
    "print('Number of   male first names:', len(MaleNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are more female first names than there are male first names.  Lets take a look at the first 5 female names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FemaleNames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we inspect the male names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaleNames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine these two lists into one list of <em style=\"color:blue;\">tagged names</em>, where a *tagged name* is a pair of the form\n",
    "$$ (\\textrm{name}, \\textrm{gender}) \\quad \\mbox{such that $\\textrm{gender} \\in \\{\\texttt{'f'},\\texttt{'m'}\\}$.}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = [(n, 'm') for n in MaleNames] + [(n, 'f') for n in FemaleNames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to test whether it is possible to predict the gender of a given name using a <em style=\"color:blue;\">Naive Bayes</em> classifier.  In order to be able to make a quantitative assessment of the <em style=\"color:blue;\">accuracy</em> of the classifier, we have to split our data into a <em style=\"color:blue;\">training</em> dataset and a <em style=\"color:blue;\">testing</em> dataset.  To minimize any bias, the assignment of the names into those datasets should be done <em style=\"color:blue;\">randomly</em>.  In order for our results to be <em style=\"color:blue;\">reproducible</em>, we set a <em style=\"color:blue;\">seed</em> for the random number generator.  This ensures that the random number generator will always behave the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "random.shuffle(Names)\n",
    "len(Names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign the majority of the names to the training set.  Roughly 10% of the data are assigned to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = Names[:7000], Names[7000:]\n",
    "len(test_set)/(len(Names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to decide the features that we want to use in order predict the gender of a name.  Our first attempt to predict the gender of a word uses just a single feature. This feature is the substring containing the last two characters of the name.  \n",
    "\n",
    "The <em style=\"color:blue;\">classifiers</em> that are already implemented in `NLTK` assume a special format for the features: The features of an object to be classified have to be implemented as a <em style=\"color:blue;\">dictionary</em>.  The keys of the features are supposed to be short descriptions of the features.  Later, we will try to increase the accuracy of our prediction by adding more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return { 'ending': word[-2:] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function on the name `'Hugo'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features('Hugo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to transform the names in our training set into features in order to train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_features = [(gender_features(n), g) for (n, g) in train_set]\n",
    "train_set_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train our first classifier.  To begin with, we use a `NaiveBayesClassifier`, which is already predefined in the module `nltk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether this classifier can predict the gender of the name `Hugo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classify(gender_features('Hugo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has correctly predicted the gender of `'Hugo'` to be *male*.  But before we get too excited, we should check the accuracy of the classifier on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, train_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this is our first attempt, an accuracy of 80% is not too bad. After all, so far we are using just a single feature.  The question is, whether our classifier is able to <em style=\"color:blue;\">generalize</em> its predictions to examples it has not seen before.  In order to answer this question we have to use the <em style=\"color:blue;\">test set</em>.  Again, we first have to transform the names from the test set into features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_features = [(gender_features(n), g) for (n, g) in test_set]\n",
    "nltk.classify.accuracy(classifier, test_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance on the test set is slightly worse, but given that we have a <em style=\"color:blue;\">bias</em> of 20%, there is no need to worry about a <em style=\"color:blue;\">variance</em> of 2% at this point.  Of course, this remark only holds if we assume that the so called <em style=\"color:blue;\">Bayes optimal error</em> is close to 0%.  If, instead, the Bayes optimal error would be, say, 19%, then we can never achieve an accuracy that is better than 81%. In that case the difference of 2% between the test set and the training set would have to be investigated further, because it is then more promising to reduce this error than to try to reduce the 1% that separates the error on the training set from the best possible error.  Of course, initially we do not know the Bayes optimal error.  For now I am just assuming that it is 15% or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NaiveBayesClassifier` has a useful method called $\\texttt{show_most_informative_features}(n)$ which shows the $n$ most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, this output tell us that for 93 female names ending in `na` there is just one male name that ends in `na`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, our goal is to refine our model for gender classification by adding more features.  In order to get a better understanding, let us investigate those names that are misclassified.  We have to be careful to look at examples from the training set, not from the test set, for if we design features with respect to the test set, then the test set will now longer give us a reasonable estimate of the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [(n, g) for (n, g) in train_set \n",
    "                 if classifier.classify(gender_features(n)) != g\n",
    "         ]\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first attempt to improve our model is to add the first letter that occur in a given word.  Furthermore, we check the letters that occur in a name.  Below is the new definition of the function `gender_features` that has these new features.  We import the module `string` because it provides the function `lower` that converts a string into lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first\" ] = name[0].lower()\n",
    "    features[\"suffix\"] = name[-2:].lower()\n",
    "    for letter in string.ascii_lowercase:\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this on our old friend `'Hugo'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_features('Hugo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gender_features('Hugo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new implementation of the function `gender_features` we have 28 features, which is a lot more than what we had in our first model.  But do these additional features actually improve the performance of our model?  We can only answer this question if we train the model and test it.  Let us compute the features of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_features = [(gender_features(n), g) for (n, g) in train_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train a `NaiveBayesClassifier` with the new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check whether the accuracy for the training set has improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, train_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_features = [(gender_features(n), g) for (n, g) in test_set]\n",
    "nltk.classify.accuracy(classifier, test_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, this is an improvement, but this improvement is less than what we might have hoped for.  Let us check the 30 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the suffix is by far more important than anything else.  Therefore, we try a *brute force* approach and increase the length of the suffix feature to three characters.  After all three is more than two, so this should be an improvement.  However, we have to take care of the fact that some names have a length of just two characters.  Our new implementation of `gender_features` deals with this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first\" ] = name[0].lower()\n",
    "    if len(name) >= 3:\n",
    "        features[\"suffix\"] = name[-3:].lower()\n",
    "    else:\n",
    "        features[\"suffix\"] = name[-2:].lower()\n",
    "    for letter in string.ascii_lowercase:\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_features = [(gender_features(n), g) for (n, g) in train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier, train_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks promising.  It seems that we are on the right track.  Lets check the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_features = [(gender_features(n), g) for (n, g) in test_set]\n",
    "nltk.classify.accuracy(classifier, test_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, our new features <em style=\"color:blue;\">overfit</em> the training data and do not generalize.  Hence, we conclude that having a suffix of three characters is not helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final attempt to solve to improve the accuracy contains three ideas:\n",
    "<ol>\n",
    "    <li>Instead of just using the first character as a feature, we should use the first two characters. \n",
    "        After all, we are also using the last two characters.\n",
    "    </li>\n",
    "    <li>Often, the way the vowels of a name are connected gives a hint about the gender. </li>\n",
    "    <li>In the same way, the consonants might be helpful.  However, we will only use the set of all consonants\n",
    "        occurring in a name, not the order in which they appear.\n",
    "    </li>\n",
    "</ol>\n",
    "Furthermore, in order to reduce the overfitting we will drop the features that check the occurrence of each character individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `find_vowels`$(s)$ takes a string $s$ and strips out all characters that are not vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vowels(s):\n",
    "    return ''.join([c for c in s if c in 'aeiouy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_vowels('Hugo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `find_consonants`$(s)$ takes a string $s$ and returns a set of its consonants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_consonants(s):\n",
    "    return frozenset({c for c in s if c not in 'aeiouy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_consonants('Hugo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    name     = name.lower()\n",
    "    features = {}\n",
    "    features[\"first\" ] = name[:2]\n",
    "    features[\"suffix\"] = name[-2:]\n",
    "    features[\"vowels\"] = find_vowels(name)\n",
    "    features[\"consonants\"] = find_consonants(name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_features = [(gender_features(n), g) for (n, g) in train_set]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set_features)\n",
    "nltk.classify.accuracy(classifier, train_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_features = [(gender_features(n), g) for (n, g) in test_set]\n",
    "nltk.classify.accuracy(classifier, test_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our features occur in the list of the 30 most important features.  In order to improve our model we could try to use a classifier that is different from `NaiveBayesClassifier`.  For example, the `MaxentClassifier` is more sophisticated than the `NaiveBayesClassifier`.  However, this classifier also takes a much longer time to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_features = [(gender_features(n), g) for (n, g) in train_set]\n",
    "classifier = nltk.MaxentClassifier.train(train_set_features)\n",
    "nltk.classify.accuracy(classifier, train_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like an improvement.  Let's check the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_features = [(gender_features(n), g) for (n, g) in test_set]\n",
    "nltk.classify.accuracy(classifier, test_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, the improvement is not real: It is mostly overfitting.  The same thing happens if we try the `ConditionalExponentialClassifier`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework**:  Try to design features that improve the accuracy of the classifier on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
