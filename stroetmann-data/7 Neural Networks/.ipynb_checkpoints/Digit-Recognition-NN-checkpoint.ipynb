{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container { width:100% } \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width:100% } \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition\n",
    "\n",
    "In this notebook we show how feed-forward neural networks can be used to recognize handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we are using is stored in a <a href=\"https://docs.python.org/3/library/gzip.html\">gzipped</a>, \n",
    "<a href=\"https://docs.python.org/3/library/pickle.html\">pickled</a> file.  Therefore, we need to import the corresponding libraries to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our data is stored as tuples of `numpy` arrays, we have to import numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to show the images of the handwritten digits, we use `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import the module `random` as we are using <em style=\"color:blue\">stochastic gradient descent</em> to compute the weights of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{vectorized_result}(d)$ converts a digit $d \\in \\{0,\\cdots,9\\}$ into a `numpy` array $\\mathbf{x}$ of shape $(10, 1)$ such that we have\n",
    "$$\n",
    "\\mathbf{x}[i] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "     1 & \\mbox{if $i = d$;} \\\\\n",
    "     0 & \\mbox{otherwise}\n",
    "  \\end{array}  \n",
    "\\right.\n",
    "$$\n",
    "for all $i \\in \\{0,\\cdots,9\\}$.\n",
    "This function is used to convert a digit $d$ into the expected output of a neural network that has an output unit for every digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(d):\n",
    "    e    = np.zeros((10, 1), dtype=np.float32)\n",
    "    e[d] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_result(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `mnist.pkl.gz` contains a triple of the form\n",
    "```\n",
    "train, validate, test\n",
    "```\n",
    "Here `train` is a pair of the form `(X, y)` where\n",
    "- `X` is a numpy array of shape `(50000, 784)`,\n",
    "- `y` is a numpy array of shape `(50000, )`.\n",
    "\n",
    "For every $i \\in \\{0,\\cdots, 49,000\\}$ we have that $\\textbf{X}[i]$ is an image of a handwritten digit and $\\textbf{y}[i]$ is a digit, i.e. an element of the set \n",
    "$\\{0,\\cdots,9\\}$.\n",
    "\n",
    "The structure of `validate` and `test` is similar, but these contain only $10,000$ images each.\n",
    "\n",
    "The function $\\texttt{load_data}()$ returns a pair of the form\n",
    "$$ (\\texttt{training_data}, \\texttt{test_data}) $$\n",
    "where \n",
    "- $\\texttt{training_data}$ is a list containing 50,000 pairs $(\\textbf{x}, \\textbf{y})$       s.t. \n",
    "  - $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image, and   \n",
    "  - $\\textbf{y}$ is a 10-dimensional `numpy.ndarray` corresponding to the correct digit for \n",
    "    $\\textbf{x}$.   \n",
    "- To keep things simple, we do not use the validation data.\n",
    "- $\\texttt{test_data}$ is a list containing 10,000 pairs $(\\textbf{x}, y)$.  In each case, \n",
    "  $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image, \n",
    "  and $y \\in \\{0,\\cdots,9\\}$ is the corresponding digit value.\n",
    "\n",
    "Note that the formats for training data and test data are different.  For the training data $\\textbf{y}$ is a vector, but for the test data $y$ is a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        train, validate, test = pickle.load(f, encoding=\"latin1\")\n",
    "    print(f'shape of training data: {(train[0].shape, train[1].shape)}')\n",
    "    training_inputs    = [np.reshape(x, (784, 1)) for x in train[0]]\n",
    "    training_results   = [vectorized_result(y) for y in train[1]]\n",
    "    training_data      = list(zip(training_inputs, training_results))\n",
    "    test_inputs        = [np.reshape(x, (784, 1)) for x in test[0]]\n",
    "    test_data          = list(zip(test_inputs, test[1]))\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip([1, 2], ['a', 'b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the data in two variables: `training_data` and `test_data`. \n",
    "- `training_data` is a list of pairs of the form $(\\textbf{x}, \\textbf{y})$ where \n",
    "   $\\textbf{x}$ is a `numpy` array of shape $(784, 1)$ representing the image of a digit, \n",
    "   while $\\textbf{y}$ is a `numpy` array of shape $(10, 1)$ that is a \n",
    "   <a href=\"https://en.wikipedia.org/wiki/One-hot\">one-hot encoding</a> \n",
    "   of the digit shown in $\\textbf{x}$.\n",
    "- `test_data` is a list of pairs of the form $(\\textbf{x}, y)$ where \n",
    "   $\\textbf{x}$ is a `numpy` array of shape $(784, 1)$ representing the image of a digit, \n",
    "   while $y$ is an element of the set $\\{0,\\cdots,9\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data: ((50000, 784), (50000,))\n",
      "CPU times: user 3.33 s, sys: 244 ms, total: 3.57 s\n",
      "Wall time: 3.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{show_digit}(\\texttt{row}, \\texttt{columns}, \\texttt{offset})$ \n",
    "shows $\\texttt{row} \\cdot \\texttt{columns}$ images of the training data.  The first image shown is the image at index $\\texttt{offset}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digits(rows, columns, offset=0):\n",
    "    f, axarr = plt.subplots(rows, columns)\n",
    "    for r in range(rows):\n",
    "        for c in range(columns):\n",
    "            i     = r * columns + c + offset\n",
    "            image = 1 - training_data[i][0]\n",
    "            image = np.reshape(image, (28, 28))\n",
    "            axarr[r, c].imshow(image, cmap=\"gray\")\n",
    "            axarr[r, c].axis('off')\n",
    "    # plt.savefig(\"digits.pdf\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_digits(5, 5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the <em style=\"color:blue;\">weight matrices</em> and <em style=\"color:blue;\">biases</em> for a neural net that is \n",
    "able to recognize the digits shown in these images.  We initialize these weight matrices randomly. The function $\\texttt{rndMatrix}(\\texttt{rows}, \\texttt{cols})$ returns a matrix of shape $(\\texttt{rows}, \\texttt{cols})$ that is filled with random numbers that have a Gaussian distribution with mean $0$ and variance $\\displaystyle\\frac{1}{\\texttt{rows}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndMatrix(rows, cols):\n",
    "    return np.random.randn(rows, cols) / np.sqrt(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38128349,  0.94286697],\n",
       "       [-0.44762292, -0.02924534]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndMatrix(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{sigmoid}(x)$ computes the sigmoid of $x$, which is defined as\n",
    "$$ \\texttt{sigmoid}(x) = S(x) := \\frac{1}{1 + \\texttt{exp}(-x)}. $$ \n",
    "Since we are using NumPy to compute the exponential function, this function also works when $x$ is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{sigmoid_prime}(x)$ computes the derivative of the sigmoid function for $x$.  The implementation is based on the equation:\n",
    "$$ S'(x) = S(x) \\cdot \\bigl(1 - S(x)\\bigr) $$\n",
    "where $x$ can either be a number or a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00664806, 0.25      , 0.00664806])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_prime(np.array([-5, 0, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Network` is used to represent a \n",
    "<em style=\"color:blue\">feedforward neural network</em> with one hidden layer.\n",
    "The constructor is called with the argument `hiddenSize`.  This parameter specifies the number of neurons in the hidden layer.  The network has $28 \\cdot 28 = 784$ input nodes.  Each of the input nodes corresponds to the gray scale value of a single pixel in a $28 \\cdot 28$ gray scale image of the digit that is to be recognized.  The number of output neurons is 10.  For $i \\in \\{0,\\cdots,9\\}$, the $i$th output neuron tries to recognize the digit $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, hiddenSize):\n",
    "        self.mInputSize  = 28 * 28\n",
    "        self.mHiddenSize = hiddenSize\n",
    "        self.mOutputSize = 10\n",
    "        self.mBiasesH    = np.zeros((self.mHiddenSize, 1))   # biases hidden layer\n",
    "        self.mBiasesO    = np.zeros((self.mOutputSize, 1))   # biases output layer\n",
    "        self.mWeightsH   = rndMatrix(self.mHiddenSize, self.mInputSize)  # weights hidden layer\n",
    "        self.mWeightsO   = rndMatrix(self.mOutputSize, self.mHiddenSize) # weights output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$ and an input vector $x$ for this neural network, the function $n.\\texttt{feedforward}(x)$ compute the output of the neural network.\n",
    "The code is a straightforward implementation of the feedforward equations.  \n",
    "These equations are repeated here for convenience:\n",
    "- $\\mathbf{a}^{(1)}(\\mathbf{x}) = \\mathbf{x}$ \n",
    "- $\\mathbf{a}^{(l)}(\\mathbf{x}) = S\\Bigl( W^{(l)} \\cdot \\mathbf{a}^{(l-1)}(\\mathbf{x}) + \\mathbf{b}^{(l)}\\Bigr)$\n",
    "  for all $l \\in \\{2, 3\\}$.\n",
    "\n",
    "The input `x` is the activation of the input layer and therefore is equal to $\\mathbf{a}^{(1)}(\\mathbf{x})$.\n",
    "`AH` is the activation of the hidden layer and hence equal to $\\mathbf{a}^{(2)}(\\mathbf{x})$, while \n",
    "`AO` is the activation of the output layer and therefore equal to $\\mathbf{a}^{(3)}(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(self, x):\n",
    "    AH = sigmoid(self.mWeightsH @ x  + self.mBiasesH) # hidden layer\n",
    "    AO = sigmoid(self.mWeightsO @ AH + self.mBiasesO) # output layer\n",
    "    return AO\n",
    "\n",
    "Network.feedforward = feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $\\texttt{sgd}(\\texttt{training_data}, \\texttt{epochs}, \\texttt{mbs}, \\texttt{eta}, \\texttt{test_data})$ uses stochastic gradient descent to train the network.  The parameters are as follows:\n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list of tuples of the form $(x, y)$ where $x$ is an \n",
    "     input of the neural net and $y$ is a vector of length 10 representing the desired output. </li>\n",
    "<li> $\\texttt{epochs}$ is the number of epochs to train,</li>\n",
    "<li> $\\texttt{mbs}$ is the size of the minibatches,</li>\n",
    "<li> $\\texttt{eta}$ is the learning rate</li>\n",
    "<li> $\\texttt{test_data}$ is a list of tuples of the form $(x, y)$ where $x$ is an \n",
    "     input and $y$ is the desired output digit. \n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(self, training_data, epochs, mbs, eta, test_data):\n",
    "    n_test = len(test_data)\n",
    "    n      = len(training_data)\n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        mini_batches = [training_data[k : k+mbs] for k in range(0, n, mbs)]\n",
    "        for mini_batch in mini_batches:\n",
    "            self.update_mini_batch(mini_batch, eta)    \n",
    "        print('Epoch %2d: %d / %d' % (j, self.evaluate(test_data), n_test))\n",
    "        \n",
    "Network.sgd = sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `update_mini_batch` performs one step of gradient descent for the data from one \n",
    "mini-batch.  It receives two arguments.\n",
    "- `mini_batch` is the list of training data that constitute one mini-batch.\n",
    "- `eta` is the <em style=\"color:blue\">learning rate</em>.\n",
    "\n",
    "The implementation of `update_mini_batch` works as follows:\n",
    "- First, we initialize the vectors `nabla_BH`, `nabla_BO` and the matrices\n",
    "  `nabla_WH`, `nabla_WO` to contain only zeros.\n",
    "  - `nabla_BH` will store the gradient of the bias vector of the hidden layer.\n",
    "  - `nabla_BO` will store the gradient of the bias vector of the output layer.\n",
    "  - `nabla_WH` will store the gradient of the weight matrix of the hidden layer.\n",
    "  - `nabla_WO` will store the gradient of the weight matrix of the output layer.\n",
    "- Next, we iterate of all training examples in the mini-batch and for every training \n",
    "  example `x, y` we compute the contribution of this training example to the gradients of \n",
    "  the cost function $C$, i.e. we compute\n",
    "  $$ \\nabla_{\\mathbf{b}^{(l)}} C_{\\mathbf{x}, \\mathbf{y}} \\quad \\mbox{and} \\quad \n",
    "     \\nabla_{W^{(l)}} C_{\\mathbf{x}, \\mathbf{y}}\n",
    "  $$ \n",
    "  for the hidden layer and the output layer.  These gradients are computed by the function\n",
    "  `backprop`.\n",
    "- Finally, the bias vectors and the weight matrices are updated according to the learning \n",
    "  rate and the computed gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mini_batch(self, mini_batch, eta):\n",
    "    nabla_BH = np.zeros((self.mHiddenSize, 1))  # gradient of biases  of hidden layer\n",
    "    nabla_BO = np.zeros((self.mOutputSize, 1))  # gradient of biases  of output layer\n",
    "    nabla_WH = np.zeros((self.mHiddenSize, self.mInputSize))  # gradient of weights of hidden layer\n",
    "    nabla_WO = np.zeros((self.mOutputSize, self.mHiddenSize)) # gradient of weights of output layer\n",
    "    for x, y in mini_batch:\n",
    "        dltNbl_BH, dltNbl_BO, dltNbl_WH, dltNbl_WO = self.backprop(x, y)\n",
    "        nabla_BH += dltNbl_BH\n",
    "        nabla_BO += dltNbl_BO\n",
    "        nabla_WH += dltNbl_WH\n",
    "        nabla_WO += dltNbl_WO      \n",
    "    alpha = eta / len(mini_batch)\n",
    "    self.mBiasesH  -= alpha * nabla_BH\n",
    "    self.mBiasesO  -= alpha * nabla_BO\n",
    "    self.mWeightsH -= alpha * nabla_WH\n",
    "    self.mWeightsO -= alpha * nabla_WO\n",
    "\n",
    "Network.update_mini_batch = update_mini_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $n.\\texttt{backprop}(x, y)$ takes a training example $(x,y)$ and calculates the gradient of the cost function with respect to this training example.  This is done by implementing the \n",
    "<em style=\"color:blue\">backpropagation equations</em> shown below:\n",
    "\n",
    "$$\n",
    "\\begin{array}[h]{llr}\n",
    "  \\boldsymbol{\\varepsilon}^{(L)} = (\\mathbf{a}^{(L)} - \\mathbf{y}) \\odot S'\\bigl(\\mathbf{z}^{(L)}\\bigr)\n",
    "     & & \\mbox{(BP1v)}  \\\\\n",
    "  \\boldsymbol{\\varepsilon}^{(l)} = \\Bigl(\\bigl(W^{(l+1)}\\bigr)^\\top \\cdot \\boldsymbol{\\varepsilon}^{(l+1)}\\Bigr) \\odot\n",
    "  S'\\bigl(\\mathbf{z}^{(l)}\\bigr) & \\mbox{for all $l \\in \\{2, \\cdots, L-1\\}$} &\n",
    "  \\mbox{(BP2v)}  \\\\\n",
    "  \\nabla_{\\mathbf{b}^{(l)}} C_{\\mathbf{x}, \\mathbf{y}} = \\boldsymbol{\\varepsilon}^{(l)}\n",
    "  & \\mbox{for all $l \\in \\{2, \\cdots,L\\}$}\n",
    "  & \\mbox{(BP3v)}\n",
    "  \\\\\n",
    "  \\nabla_{W^{(l)}} C_{\\mathbf{x}, \\mathbf{y}} = \\boldsymbol{\\varepsilon}^{(l)} \\cdot \\bigl(\\mathbf{a}^{(l-1)}\\bigr)^\\top\n",
    "  & \\mbox{for all $l \\in \\{2, \\cdots,L\\}$}\n",
    "  & \\mbox{(BP4v)}\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(self, x, y):\n",
    "    # feedforward pass\n",
    "    ZH = self.mWeightsH @ x  + self.mBiasesH\n",
    "    AH = sigmoid(ZH)\n",
    "    ZO = self.mWeightsO @ AH + self.mBiasesO\n",
    "    AO = sigmoid(ZO)\n",
    "    # backwards pass, output layer\n",
    "    epsilonO = (AO - y) * sigmoid_prime(ZO)\n",
    "    nabla_BO = epsilonO\n",
    "    nabla_WO = epsilonO @ AH.transpose()\n",
    "    # backwards pass, hidden layer\n",
    "    epsilonH = (self.mWeightsO.transpose() @ epsilonO) * sigmoid_prime(ZH)\n",
    "    nabla_BH = epsilonH\n",
    "    nabla_WH = epsilonH @ x.transpose()\n",
    "    return nabla_BH, nabla_BO, nabla_WH, nabla_WO\n",
    "\n",
    "Network.backprop = backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $n.\\texttt{evaluate}(\\texttt{test_data})$ uses the test data to compute  the number of examples that are predicted correctly by the neural network $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, test_data):\n",
    "    test_results = \\\n",
    "        [(np.argmax(self.feedforward(x)), y) for x, y in test_data]\n",
    "    return sum(y1 == y2 for y1, y2 in test_results)\n",
    "\n",
    "Network.evaluate = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: 8898 / 10000\n",
      "Epoch  1: 9103 / 10000\n",
      "Epoch  2: 9179 / 10000\n",
      "Epoch  3: 9254 / 10000\n",
      "Epoch  4: 9303 / 10000\n",
      "Epoch  5: 9339 / 10000\n",
      "Epoch  6: 9360 / 10000\n",
      "Epoch  7: 9398 / 10000\n",
      "Epoch  8: 9408 / 10000\n",
      "Epoch  9: 9423 / 10000\n",
      "Epoch 10: 9432 / 10000\n",
      "Epoch 11: 9458 / 10000\n",
      "Epoch 12: 9466 / 10000\n",
      "Epoch 13: 9477 / 10000\n",
      "Epoch 14: 9477 / 10000\n",
      "Epoch 15: 9501 / 10000\n",
      "Epoch 16: 9505 / 10000\n",
      "Epoch 17: 9521 / 10000\n",
      "Epoch 18: 9510 / 10000\n",
      "Epoch 19: 9531 / 10000\n",
      "Epoch 20: 9534 / 10000\n",
      "Epoch 21: 9537 / 10000\n",
      "Epoch 22: 9547 / 10000\n",
      "Epoch 23: 9538 / 10000\n",
      "Epoch 24: 9549 / 10000\n",
      "Epoch 25: 9567 / 10000\n",
      "Epoch 26: 9563 / 10000\n",
      "Epoch 27: 9582 / 10000\n",
      "Epoch 28: 9567 / 10000\n",
      "Epoch 29: 9569 / 10000\n",
      "CPU times: user 15min 39s, sys: 1min, total: 16min 39s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(1)\n",
    "net = Network(40)\n",
    "net.sgd(training_data, 30, 10, 0.1, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the number of parameters of our network? \n",
    "- The hidden layer has 40 neurons that each have a bias parameter and 784 \n",
    "  weight parameters for the connections to the input nodes.\n",
    "- The output layer has 10 neurons that each have a bias parameter and 40 \n",
    "  weight parameters for the connections to the hidden layer.\n",
    "  \n",
    "Therefore the network has \n",
    "$$ 40 \\cdot (1 + 784) + 10 \\cdot (1 + 40) = 31,810 $$\n",
    "parameters.  As we have $50,000$ training data and every training datum gives rise to 10 equations, we shouldn't be too worried about over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40 * (1 + 784) + 10 * (1 + 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
