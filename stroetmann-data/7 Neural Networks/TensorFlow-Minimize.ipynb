{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width:100% } \n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to find the minimum of the function\n",
    "$$ x \\mapsto \\exp(x) - 2 \\cdot x^2 + 1 $$\n",
    "using the <a href=\"https://en.wikipedia.org/wiki/TensorFlow\">TensorFlow</a> library. \n",
    "We plot this function using `numpy`, `matplotlib`, and `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the function $x \\mapsto \\exp(x) - 2 \\cdot x^2 + 1$ as a Python function that can take a \n",
    "`numpy` array as its argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm(x):\n",
    "    return np.exp(x) - 2 * x**2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot this function for all $x$ such that $-1 \\leq x \\leq 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.arange(-1.0, 3, 0.01)\n",
    "Ys = fm(Xs)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.set(style='whitegrid')\n",
    "sns.lineplot(Xs, Ys, color='b')\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.ylim(-0.5, 3.0)\n",
    "plt.xlim(-1.0, 3,0)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('x |-> exp(x) - 2 * x**2 + 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $x \\geq 0$, the function $f$ seems to have a minimum somewhere between $2.0$ and $2.5$.  We want to compute this minimum numerically using <font style=\"color:blue;\">gradient descent</font> via \n",
    "<a href=\"https://www.tensorflow.org\">TensorFlow</a>, but we do not want to compute the gradient of \n",
    "$f$ ourselves.  In order to install `tensorflow`, the following command can be used:\n",
    "```\n",
    "    conda install -c conda-forge tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a variable $x$.  Later, we will define the function \n",
    "$$ f(x) := \\exp(x) - 2 \\cdot x^2 + 1 $$\n",
    "and compute the value $x_0$ such that $f(x_0) \\leq f(x)$ for all $x \\geq 0$.  The variable $x$ is a single precision variable, hence we use <tt>tf.float32</tt> as its data type.  The variable is initialized to the value $1$.  We also assign a *name* to it, but this name is completely optional, since this name is only used when we \n",
    "print the variable.  Hence it is only useful for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(1, dtype=tf.float32, name='var_x')\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a variable that contains only a single number and not an array or a matrix, its shape is \n",
    "<tt>()</tt>.  The string `'var_x:0'` is an internal name used by TensorFlow to manage this variable. \n",
    "Note that TensorFlow has appended the string <tt>':0'</tt> at the end of the string `var_x` in order to ensure that this name is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a <font style=\"color:blue;\">cost function</font> $f$ using `tensorflow` next.  Mathematically, \n",
    "this cost function is the function $f$ from above:\n",
    "$$ f(x) = \\exp(x) - 2 \\cdot x^2 + 1 $$\n",
    "Note that we have used the variable `x` defined above in the right hand side of this definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.exp(x) - 2 * x**2 + 1\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, `f` as defined above is a term made up from constants and variables.  Technically, `f` is an object of the class `Tensor`.  Since the last operation that is executed when computing $f(x)$ is the\n",
    "addition of $1$ and, conceptually, a tensor is just an <font style=\"color:blue;\">abstract syntax tree</font> representing an expression, this tensor has the internal name `add:0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the function $f$, we can now try to minimize it via \n",
    "<font style=\"color:blue;\">gradient descent</font>.  The module <tt>tf.train</tt> contains various algorithms for minimization.  `tf.train.GradientDescentOptimzer` is the optimizer that implements one step of <font style=\"color:blue;\">gradient descent</font>.  When doing *gradient descent*, we will use a <font style=\"color:blue;\">learning rate</font> $\\alpha$ of $0.2$.  Using a smaller learning rate would slow down *gradient descent*, but if we would use a learning rate that is significantly larger, then gradient descent would start to <font style=\"color:blue;\">oscillate</font> and \n",
    "hence *gradient descent* would **not converge** and, therefore, it would not be able to find the minimum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α     = 0.2\n",
    "train = tf.train.GradientDescentOptimizer(α).minimize(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow issues lot of deprecation warnings.  As they are quite annoying and we can't do anything about the issues, let us suppress further warnings.  This is done by setting the environment variable `TF_CPP_MIN_LOG_LEVEL` to the value of `'2'`.  To this end we have to use the module `os`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, <tt>train</tt> is just an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start running the *gradient descent* optimizer, we first have to create an \n",
    "<font style=\"color:blue;\">initializer object</font> that can later be used to initialize **all** of our variables.  Of course, in this simple example there is just one variable <tt>x</tt>, but in general, there could be many different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start a TensorFlow <font style=\"color:blue;\">session</font> that performs the real work.  <tt>Session</tt> is a TensorFlow class that has a method called <tt>run</tt>.  This method can be used to \n",
    "<font style=\"color:blue;\">evaluate</font> a variable or to perform one step of an iterative algorithm like <font style=\"color:blue;\">gradient descent</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)         # initialize x to 1\n",
    "    for k in range(12):       # we do 12 steps of gradient descent\n",
    "        session.run(train)    # run one step of gradient descent \n",
    "        v = session.run(x)    # evaluate x so we can print it\n",
    "        print('%2d: %f' % (k, v)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computation shows that the function $f$ takes its minimal value at $x \\approx 2.153292$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although we have used <font style=\"color:blue;\">gradient descent</font>, we never had to calculate the \n",
    "<font style=\"color:blue;\">derivative</font> of the function $f$.  This derivative has been calculated by TensorFlow instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
